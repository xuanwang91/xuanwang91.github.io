---
title: 'ACL 2024 Tutorial'
date:   TBD
permalink: /2024-8-12-acl24-tutorial
tags:
  - acl
  - tutorial
  - 2024
---

# AI for Science in the Era of Large Language Models

[Zhenyu Bi](https://www.linkedin.com/in/zhenyu-bi-817814178/), [Minghao Xu](https://chrisallenming.github.io/), [Jian Tang](https://jian-tang.com/), [Xuan Wang](https://xuanwang91.github.io/)

Department of Computer Science, Virginia Tech, USA

Mila - Quebec AI Institute, Canada

Time: **TBD**

Location: **Bangkok, Thailand**


## Abstract:
The capabilities of AI in the realm of science span a wide spectrum, from the atomic level, where it solves partial differential equations for quantum systems, to the molecular level, predicting chemical or protein structures, and even extending to societal predictions like infectious disease outbreaks. Recent advancements in large language models (LLMs), exemplified by models like ChatGPT, have showcased significant prowess in tasks involving natural language, such as translating languages, constructing chatbots, and answering questions. When we consider scientific data, we notice a resemblance to natural language in terms of sequences â€“ scientific literature and health records presented as text, bio-omics data arranged in sequences, or sensor data like brain signals. The question arises: Can we harness the potential of these recent LLMs to drive scientific progress? In this tutorial, we will explore the application of large language models to three crucial categories of scientific data: 1) textual data, 2) biomedical sequences, and 3) brain signals. Furthermore, we will delve into LLMs' challenges in scientific research, including ensuring trustworthiness, achieving personalization, and adapting to multi-modal data representation.

## Tutorial Recording:
TBD


## Slides:
TBD

